{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3449e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breast Cancer Detection Using Machine Learning (Binary Classification)\n",
    "\n",
    "#This notebook builds a breast cancer classifier using:\n",
    "#- Logistic Regression\n",
    "#- Decision Tree\n",
    "#- Random Forest\n",
    "#- Artificial Neural Network (ANN)\n",
    "\n",
    "#We:\n",
    "#1. Load and explore the data  \n",
    "#2. Preprocess it (encode labels, handle missing values, scale features)  \n",
    "#3. Train and evaluate models  \n",
    "#4. Optionally explore PCA and K-Means clustering  \n",
    "#5. Predict on a new (synthetic) patient sample\n",
    "\n",
    "## CNN on BreakHis Histopathology Images\n",
    "\n",
    "#In this section, I use the BreakHis breast histopathology image dataset\n",
    "#organized into `train/val/test` and `benign/malignant` folders.\n",
    "#I train a Convolutional Neural Network (CNN) to classify tumor images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2397b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97499e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv(\"breast-cancer.csv\")\n",
    "\n",
    "# Show basic info\n",
    "print(\"First 5 rows:\")\n",
    "display(dataset.head())\n",
    "\n",
    "print(\"\\nColumns:\")\n",
    "print(dataset.columns.tolist())\n",
    "\n",
    "print(\"\\nShape (rows, columns):\", dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bce3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary statistics for numeric features:\")\n",
    "display(dataset.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "sns.countplot(x='diagnosis', data=dataset)\n",
    "plt.title(\"Count of Benign (B) vs Malignant (M)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e39ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.hist(figsize=(20, 20))\n",
    "plt.suptitle(\"Feature Distributions\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164dc5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# === 3.1 Drop useless columns ===\n",
    "# 'id' is not useful for prediction, we drop it if present\n",
    "if 'id' in dataset.columns:\n",
    "    dataset = dataset.drop('id', axis=1)\n",
    "\n",
    "# === 3.2 Encode target label ===\n",
    "# diagnosis: M/B --> 1/0\n",
    "label_encoder = LabelEncoder()\n",
    "dataset['diagnosis'] = label_encoder.fit_transform(dataset['diagnosis'])\n",
    "# Typically: B -> 0, M -> 1\n",
    "\n",
    "# === 3.3 Split into features (X) and target (y) ===\n",
    "X = dataset.drop(columns=['diagnosis'])\n",
    "y = dataset['diagnosis']\n",
    "\n",
    "print(\"Feature columns:\")\n",
    "print(X.columns.tolist())\n",
    "print(\"\\nX shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# === 3.4 Handle missing values ===\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# === 3.5 Train–test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\nTrain shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "\n",
    "# === 3.6 Feature scaling ===\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save scaler and imputer for later use (e.g., single-patient prediction)\n",
    "joblib.dump(scaler, \"scaler.save\")\n",
    "joblib.dump(imputer, \"imputer.save\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0d219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4.1 Logistic Regression ===\n",
    "\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_log = log_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_log, target_names=['Benign (0)', 'Malignant (1)']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d1bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4.2 Decision Tree Classifier ===\n",
    "\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "tree_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_tree = tree_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"=== Decision Tree Classifier ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tree))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tree))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_tree, target_names=['Benign (0)', 'Malignant (1)']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bad1372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# SECTION A — RANDOM FOREST TRAINING & EVALUATION\n",
    "# ===============================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Create a stronger Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,         # more trees → better accuracy\n",
    "    max_depth=None,           # allow full depth\n",
    "    random_state=42,\n",
    "    class_weight='balanced'   # handles any imbalance\n",
    ")\n",
    "\n",
    "# IMPORTANT: train on the SCALED data (like Logistic Regression and ANN)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set (also scaled)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_conf_mat = confusion_matrix(y_test, y_pred_rf)\n",
    "rf_report = classification_report(y_test, y_pred_rf, target_names=['Benign (0)', 'Malignant (1)'])\n",
    "\n",
    "print(\"===== RANDOM FOREST: Training Results =====\")\n",
    "print(\"Accuracy:\", rf_accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", rf_conf_mat)\n",
    "print(\"\\nClassification Report:\\n\", rf_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cdbfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# SECTION B — RANDOM FOREST PREDICTION ON NEW DATA\n",
    "# ===============================\n",
    "\n",
    "# ---- Synthetic Benign Example ----\n",
    "example_patient = pd.DataFrame({\n",
    "    'radius_mean': [12.0],\n",
    "    'texture_mean': [15.0],\n",
    "    'perimeter_mean': [78.0],\n",
    "    'area_mean': [450.0],\n",
    "    'smoothness_mean': [0.08],\n",
    "    'compactness_mean': [0.07],\n",
    "    'concavity_mean': [0.04],\n",
    "    'concave points_mean': [0.03],\n",
    "    'symmetry_mean': [0.18],\n",
    "    'fractal_dimension_mean': [0.06],\n",
    "    'radius_se': [0.3],\n",
    "    'texture_se': [1.1],\n",
    "    'perimeter_se': [2.5],\n",
    "    'area_se': [20.0],\n",
    "    'smoothness_se': [0.005],\n",
    "    'compactness_se': [0.01],\n",
    "    'concavity_se': [0.005],\n",
    "    'concave points_se': [0.004],\n",
    "    'symmetry_se': [0.015],\n",
    "    'fractal_dimension_se': [0.003],\n",
    "    'radius_worst': [14.0],\n",
    "    'texture_worst': [20.0],\n",
    "    'perimeter_worst': [95.0],\n",
    "    'area_worst': [550.0],\n",
    "    'smoothness_worst': [0.09],\n",
    "    'compactness_worst': [0.10],\n",
    "    'concavity_worst': [0.05],\n",
    "    'concave points_worst': [0.04],\n",
    "    'symmetry_worst': [0.20],\n",
    "    'fractal_dimension_worst': [0.07]\n",
    "})\n",
    "\n",
    "# Align columns to X just to be safe\n",
    "example_patient = example_patient[X.columns]\n",
    "\n",
    "# Scale with SAME scaler\n",
    "example_scaled = scaler.transform(example_patient)\n",
    "\n",
    "# Predict\n",
    "rf_prediction = rf_model.predict(example_scaled)\n",
    "print(\"\\n===== RANDOM FOREST: Synthetic Patient Prediction =====\")\n",
    "print(\"Predicted Class:\", rf_prediction[0])\n",
    "\n",
    "if rf_prediction[0] == 1:\n",
    "    print(\"Final Result: MALIGNANT (1)\")\n",
    "else:\n",
    "    print(\"Final Result: BENIGN (0)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8885c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Real Malignant Example from Dataset ----\n",
    "\n",
    "real_malignant_example = X[y == 1].iloc[[0]]   # get first malignant row\n",
    "\n",
    "print(\"\\n===== REAL MALIGNANT PATIENT DATA =====\")\n",
    "display(real_malignant_example)\n",
    "\n",
    "# Impute (in case needed) and scale\n",
    "mal_imputed = imputer.transform(real_malignant_example)\n",
    "mal_scaled = scaler.transform(mal_imputed)\n",
    "\n",
    "# Predict\n",
    "mal_pred = rf_model.predict(mal_scaled)[0]\n",
    "\n",
    "print(\"\\n===== RANDOM FOREST: Real Malignant Prediction =====\")\n",
    "print(\"Predicted Class:\", mal_pred)\n",
    "\n",
    "if mal_pred == 1:\n",
    "    print(\"Final Result: MALIGNANT (1)\")\n",
    "else:\n",
    "    print(\"Final Result: BENIGN (0)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4.3 Artificial Neural Network (ANN) ===\n",
    "\n",
    "# Define input dimension based on number of features\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "print(\"Input dimension for ANN:\", input_dim)\n",
    "\n",
    "ann = Sequential()\n",
    "ann.add(Dense(units=6, activation='relu', kernel_initializer='uniform', input_dim=input_dim))\n",
    "ann.add(Dense(units=6, activation='relu', kernel_initializer='uniform'))\n",
    "ann.add(Dense(units=1, activation='sigmoid', kernel_initializer='uniform'))\n",
    "\n",
    "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = ann.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    batch_size=10,\n",
    "    epochs=50,      \n",
    "    verbose=0       # set to 1 to see training progress\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "loss, acc = ann.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "print(\"=== ANN (Neural Network) ===\")\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", acc)\n",
    "\n",
    "# Save model\n",
    "ann.save(\"ann_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training accuracy and loss over epochs\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('ANN Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('ANN Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8434fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_tree)\n",
    "disp = ConfusionMatrixDisplay(conf_matrix, display_labels=['Benign (0)', 'Malignant (1)'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Decision Tree')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6.1 PCA (2D) ===(reduce dimension)\n",
    "\n",
    "pca = PCA(n_components=2)#(2D->PC1,PC2)\n",
    "X_pca = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "print(\"Explained variance ratio (2 components):\", pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.5)\n",
    "plt.title(\"PCA Projection (Train Data)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()\n",
    "\n",
    "# === 6.2 KMeans clustering on PCA-reduced data ===(unsupervised learning)\n",
    "\n",
    "k = 2 #3 groups,clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(X_pca)\n",
    "\n",
    "sil_score = silhouette_score(X_pca, cluster_labels)\n",
    "print(\"Silhouette Score (KMeans on PCA-reduced data):\", sil_score)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "colors = ['red', 'green', 'blue']\n",
    "for i in range(k):\n",
    "    plt.scatter(\n",
    "        X_pca[cluster_labels == i, 0],\n",
    "        X_pca[cluster_labels == i, 1],\n",
    "        color=colors[i],\n",
    "        label=f\"Cluster {i+1}\",\n",
    "        alpha=0.6\n",
    "    )\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], color='black', marker='X', s=100, label='Centers')\n",
    "\n",
    "plt.title(\"KMeans Clusters (PCA-reduced data)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296436c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names in correct order\n",
    "feature_names = X.columns.tolist()\n",
    "print(\"Feature names (in order):\")\n",
    "print(feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27584929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7. Prediction for a new synthetic patient ===\n",
    "\n",
    "# Load imputer, scaler, and ANN model\n",
    "imputer_loaded = joblib.load(\"imputer.save\")\n",
    "scaler_loaded = joblib.load(\"scaler.save\")\n",
    "ann_loaded = load_model(\"ann_model.h5\")\n",
    "\n",
    "# Example observation: fill ALL required feature values\n",
    "# Here I'll show an example assuming all 30 original features are present.\n",
    "# Replace these numbers with realistic values or those in your report.\n",
    "observation_data = {\n",
    "   'radius_mean': [10.5],\n",
    "    'texture_mean': [14.0],\n",
    "    'perimeter_mean': [70.0],\n",
    "    'area_mean': [330.0],\n",
    "    'smoothness_mean': [0.08],\n",
    "    'compactness_mean': [0.05],\n",
    "    'concavity_mean': [0.02],\n",
    "    'concave points_mean': [0.01],\n",
    "    'symmetry_mean': [0.17],\n",
    "    'fractal_dimension_mean': [0.06],\n",
    "    'radius_se': [0.3],\n",
    "    'texture_se': [1.1],\n",
    "    'perimeter_se': [2.0],\n",
    "    'area_se': [20.0],\n",
    "    'smoothness_se': [0.005],\n",
    "    'compactness_se': [0.01],\n",
    "    'concavity_se': [0.005],\n",
    "    'concave points_se': [0.004],\n",
    "    'symmetry_se': [0.015],\n",
    "    'fractal_dimension_se': [0.003],\n",
    "    'radius_worst': [12.5],\n",
    "    'texture_worst': [16.0],\n",
    "    'perimeter_worst': [84.0],\n",
    "    'area_worst': [460.0],\n",
    "    'smoothness_worst': [0.095],\n",
    "    'compactness_worst': [0.08],\n",
    "    'concavity_worst': [0.03],\n",
    "    'concave points_worst': [0.02],\n",
    "    'symmetry_worst': [0.20],\n",
    "    'fractal_dimension_worst': [0.07]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create DataFrame in the correct column order\n",
    "# Ensure we align with X.columns\n",
    "observation_df = pd.DataFrame(observation_data)[X.columns]\n",
    "\n",
    "# 1) Impute (if needed)\n",
    "obs_imputed = imputer_loaded.transform(observation_df)\n",
    "\n",
    "# 2) Scale\n",
    "obs_scaled = scaler_loaded.transform(obs_imputed)\n",
    "\n",
    "# 3) Predict with ANN\n",
    "prob = ann_loaded.predict(obs_scaled)[0, 0]\n",
    "pred_class = int(prob > 0.5)\n",
    "\n",
    "print(f\"Predicted probability of malignant: {prob:.3f}\")\n",
    "print(\"Predicted class:\", pred_class, \"(1 = malignant, 0 = benign)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2702e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "#  CNN: Load Pre-Trained Model\n",
    "# ============================\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Image size used during training\n",
    "img_height = 150\n",
    "img_width = 150\n",
    "\n",
    "# Load your trained CNN model\n",
    "cnn = load_model(\"cnn_model_colab.h5\")\n",
    "\n",
    "print(\"Loaded CNN Model:\")\n",
    "cnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab10300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cnn(image_path):\n",
    "    img = image.load_img(image_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    prob = cnn.predict(img_array)[0][0]\n",
    "    label = \"Malignant (1)\" if prob > 0.5 else \"Benign (0)\"\n",
    "\n",
    "    plt.imshow(image.load_img(image_path))\n",
    "    plt.title(f\"Prediction: {label}\\nProbability of malignant = {prob:.4f}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    return prob, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464574c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "#  CNN: Run Prediction on an Image\n",
    "# ============================\n",
    "\n",
    "#image_path = \"C:\\\\Users\\\\User\\\\Desktop\\\\Computer Science\\\\Artificial Intelligence\\\\AI Project\\\\Dataset\\\\benign\\\\SOB\\\\adenosis\\\\SOB_B_A_14-22549AB\\\\40X\\\\SOB_B_A-14-22549AB-40-014.png\"   #Balignant\n",
    "image_path = \"C:\\\\Users\\\\User\\\\Desktop\\\\Computer Science\\\\Artificial Intelligence\\\\AI Project\\\\Dataset\\\\malignant\\\\SOB\\\\ductal_carcinoma\\\\SOB_M_DC_14-2523\\\\40X\\\\SOB_M_DC-14-2523-40-010.png\"\n",
    "prob, label = predict_cnn(image_path)\n",
    "\n",
    "print(\"\\nRaw malignant probability:\", prob)\n",
    "print(\"Predicted class:\", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a036c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#img_height = 150\n",
    "#img_width = 150\n",
    "#batch_size = 32 --each batch has 32 images\n",
    "\n",
    "#train_dir = \"Dataset/breakhis_dataset/train\"\n",
    "#val_dir   = \"Dataset/breakhis_dataset/val\"\n",
    "#test_dir  = \"Dataset/breakhis_dataset/test\"\n",
    "\n",
    "#Normalization:\n",
    "#train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#val_datagen   = ImageDataGenerator(rescale=1./255)\n",
    "#test_datagen  = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#train_generator = train_datagen.flow_from_directory(\n",
    " #   train_dir,\n",
    "  #  target_size=(img_height, img_width),\n",
    "   # batch_size=batch_size,\n",
    "    #class_mode='binary'\n",
    "#)\n",
    "\n",
    "#val_generator = val_datagen.flow_from_directory(\n",
    " #   val_dir,\n",
    "  #  target_size=(img_height, img_width),\n",
    "   # batch_size=batch_size,\n",
    "    #class_mode='binary'\n",
    "#)\n",
    "\n",
    "#test_generator = test_datagen.flow_from_directory(\n",
    " #   test_dir,\n",
    "  #  target_size=(img_height, img_width),\n",
    "   # batch_size=batch_size,\n",
    "    #class_mode='binary'\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ae20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs = 10  # increase to 20 if you want better accuracy\n",
    "\n",
    "#history_cnn = cnn.fit(\n",
    " #   train_generator,\n",
    "  #  epochs=epochs,\n",
    "   # validation_data=val_generator\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611e18b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_loss, test_acc = cnn.evaluate(test_generator)\n",
    "#print(\"CNN Test Accuracy:\", test_acc)\n",
    "#print(\"CNN Test Loss:\", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc5b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.figure(figsize=(10,4))\n",
    "\n",
    "#plt.subplot(1,2,1)\n",
    "#plt.plot(history_cnn.history['accuracy'], label='train acc')\n",
    "#plt.plot(history_cnn.history['val_accuracy'], label='val acc')\n",
    "#plt.title('CNN Accuracy')\n",
    "#plt.legend()\n",
    "\n",
    "#plt.subplot(1,2,2)\n",
    "#plt.plot(history_cnn.history['loss'], label='train loss')\n",
    "#plt.plot(history_cnn.history['val_loss'], label='val loss')\n",
    "#plt.title('CNN Loss')\n",
    "#plt.legend()\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de61b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.preprocessing import image\n",
    "#import numpy as np\n",
    "\n",
    "#img_path = \"TestImages/myTestImageB.png\"  # <- adjust if in a different folder\n",
    "\n",
    "# 1) Load image and resize to same size used in training\n",
    "#img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "\n",
    "# 2) Convert to array\n",
    "#img_array = image.img_to_array(img)\n",
    "\n",
    "# 3) Scale like training data (rescale=1./255)\n",
    "#img_array = img_array / 255.0\n",
    "\n",
    "# 4) Add batch dimension: shape (1, img_height, img_width, 3)\n",
    "#img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# 5) Predict\n",
    "#prob = cnn.predict(img_array)[0][0]  # probability of class 1 (malignant)\n",
    "\n",
    "#print(\"Raw predicted probability of malignant:\", prob)\n",
    "\n",
    "#if prob > 0.5:\n",
    " #   print(\"Predicted class: 1 (Malignant)\")\n",
    "#else:\n",
    " #   print(\"Predicted class: 0 (Benign)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
